{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from face_recognition import face_landmarks\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "face = Image.open(\"images/thispersondoesnotexist.jpg\")\n",
    "face_array = np.array(face)\n",
    "mask = Image.open(\"images/mustache.png\")\n",
    "mask = mask.crop(mask.getbbox())\n",
    "# create draw object for face image\n",
    "draw = ImageDraw.Draw(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coeffs(pa, pb):\n",
    "    \"\"\"\n",
    "    find coefficientes (so)\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    for p1, p2 in zip(pa, pb):\n",
    "        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n",
    "        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n",
    "\n",
    "    A = np.matrix(matrix, dtype=np.float)\n",
    "    B = np.array(pb).reshape(8)\n",
    "\n",
    "    res = np.dot(np.linalg.inv(A.T * A) * A.T, B)\n",
    "    return np.array(res).reshape(8)\n",
    "\n",
    "\n",
    "def transform4point(img, src, dst):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    lx, ly = img.size\n",
    "    mapping = find_coeffs(dst, src)\n",
    "    img = img.transform((lx*10, ly*10), Image.PERSPECTIVE, mapping)\n",
    "    img = img.crop(img.getbbox())\n",
    "    lx, ly = img.size\n",
    "    # img = img.thumbnail((lx*3,ly*3))\n",
    "\n",
    "    # img = img.resize((lx*2,ly*2))#, Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def midPoint(a, b, ratio):\n",
    "    \"\"\"\n",
    "    returns the point in between a and b at a distance of ratio*(b-a)\n",
    "    :param a: point to start the walk\n",
    "    :param b: point to walk to\n",
    "    :return: point between a and b, when you walked :ratio: part of total\n",
    "    \"\"\"\n",
    "    ax, ay = a\n",
    "    bx, by = b\n",
    "    dx = (bx-ax)*ratio\n",
    "    dy = (by-ay)*ratio\n",
    "    return ax+dx, ay+dy\n",
    "\n",
    "\n",
    "def quadrilateral(landmark, normalize=True):\n",
    "    \"\"\"\n",
    "    Find convenient quadrilateral from 5 landmark points for transformation of mask\n",
    "    The ratios are based on a perfect frontal face.\n",
    "    This function can be used for 5 or 68 landmarkpoint by small and large model of the face_landmarks() function\n",
    "\n",
    "    :param landmark: landmark points based on small or large model from face_recognition\n",
    "    :param normalize: if True, the smalles xy values are 0. If xy coordinates are given, the smalles xy values will be those coordinates\n",
    "    :return: 4 xy tuples with corner values of quadrilateral [top_left, top_right, botton_left, bottom_right]\n",
    "    \"\"\"\n",
    "    if len(landmark) == 3:  # model=\"small\"\n",
    "        lEyeOut, lEyeIn = landmark[\"left_eye\"]\n",
    "        rEyeOut, rEyeIn = landmark[\"right_eye\"]\n",
    "        noseTip = landmark[\"nose_tip\"][0]\n",
    "    elif len(noseTip) == 9: # model=\"large\"\n",
    "        lEyeOut = landmark[\"left_eye\"][0]\n",
    "        lEyeIn = landmark[\"left_eye\"][3]\n",
    "        rEyeOut = landmark[\"right_eye\"][3]\n",
    "        rEyeIn = landmark[\"right_eye\"][0]\n",
    "        noseTip = landmark[\"nose_tip\"][2]\n",
    "    else:\n",
    "        raise ValueError(\"Doesn't recognize landmarks; len(nose_tip) should be 1 or 5\")\n",
    "    topLeft     = midPoint(a=lEyeOut, b=lEyeIn,  ratio=0.31)\n",
    "    topRight    = midPoint(a=rEyeOut, b=rEyeIn,  ratio=0.31)\n",
    "    bottomLeft  = midPoint(a=lEyeOut, b=noseTip, ratio=0.18)\n",
    "    bottomRight = midPoint(a=rEyeOut, b=noseTip, ratio=0.18)\n",
    "    quad = [topLeft, topRight, bottomLeft, bottomRight]\n",
    "    \n",
    "    # normalize quadrilateral to (0,0) or give xy tuple/list\n",
    "    if normalize==True:\n",
    "        xmin, ymin = [min(a) for a in zip(*quad)]\n",
    "        quad = [(x-xmin, y-ymin) for x, y in quad]\n",
    "    elif type(normalize) in [tuple, list]:\n",
    "        if len(normalize) == 2:\n",
    "            xmin, ymin = [min(a) for a in zip(*quad)]\n",
    "            xmin, ymin = xmin+normalize[0], ymin+normalize[1]\n",
    "            quad = [(x-xmin, y-ymin) for x, y in quad]\n",
    "\n",
    "    return quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx, ly = mask.size\n",
    "src = [(0,0), (lx,0), (0,ly), (lx,ly)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = face_landmarks(face_array, model=\"small\")\n",
    "for landmark in landmarks:\n",
    "    dst = quadrilateral(landmark) # TODO add large model\n",
    "    transMask = transform4point(img=mask, src=src, dst=dst)\n",
    "    nose = landmark[\"nose_tip\"][0] # TODO add large model\n",
    "    face.paste(transMask, (nose[0] - transMask.size[0]//2, nose[1]), transMask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "face.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transMask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(107, 456, 4)\n"
     ]
    }
   ],
   "source": [
    "def refImage(PILimage, x, y):\n",
    "    imgArray = np.array(PILimage)        # convert to numpy array\n",
    "    print(imgArray.shape) \n",
    "    refArray = np.zeros(imgArray.shape)[:,:,0] # create black image array\n",
    "    refArray[y,x] = 255                  # with a white pixel at the reference point\n",
    "    return Image.fromarray(refArray)     # convert to PIL image object\n",
    "\n",
    "refmask = refImage(mask, x=250, y=100)\n",
    "refmask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(107, 456, 4)\n"
     ]
    }
   ],
   "source": [
    "maks = Image.open(\"images/mustache.png\")\n",
    "refmask = refImage(mask, x=250, y=100)\n",
    "transMask = transform4point(img=mask, src=src, dst=dst)\n",
    "transMask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "type((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}